#!/usr/bin/python3
import sys
import time
import socket
import ssl
import json
from ssl import SSLContext
from bs4 import BeautifulSoup
from pprint import pprint
import warnings
warnings.filterwarnings('ignore')

def http_cache(response):
    soup = BeautifulSoup(response, 'html.parser')
    with open("cache_file.txt", "w") as file:
        file.write(soup.decode('latin-1'))
        
def parse_url(url):
    # Extract host, port, and path from URL
    url_parts = url.split("/")
    host_port = url_parts[2].split(":")
    host = host_port[0]
    port = int(host_port[1]) if len(host_port) > 1 else 80
    path = "/" + "/".join(url_parts[3:])
    return host, port, path

def make_http_request(url,):
    host, port, path = parse_url(url)
    print(f"Host: {host}\nPort: {port}\nPath: {path}")
    
    request = f"GET {path} HTTP/1.1\r\nHost:{host}\r\nConnection: close\r\n\r\n"
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as client_socket:
            client_socket.connect((host, 80))
            client_socket.sendall(request.encode("utf-8"))
            response = b''
            while True:
                data = client_socket.recv(1024)
                if not data:
                    break
                response += data

            client_socket.close()

    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)
    
    content_type = ""
    for header in response.split(b'\r\n'):
        if header.startswith(b'Content-Type:'):
            content_type = header.decode().split(': ')[1]
            break

    # if "application/json" in content_type:
    #     pprint(response)
    #     # return json.loads(response.split(b'\r\n\r\n')[1])
    # else:
    soup = BeautifulSoup(response, 'html.parser')
    while soup.decode().startswith("HTTP/1.1 30"):
        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        ssl_socket = ssl.wrap_socket(client_socket)

        # Extract new URL from the response
        new_url = ""
        for header in response.split(b'\r\n'):
            if header.startswith(b'Location:'):
                new_url = header.decode().split(': ')[1]
                break
        
        print(f"Redirecting to: {new_url}")

        host, port, path = parse_url(new_url)
        port = 443
        print(f"Host: {host}\nPort: {port}\nPath: {path}")
        request = f"GET {path} HTTP/1.1\r\nHost:{host}\r\nConnection: close\r\n\r\n"

        ssl_socket.connect((host, port))
        ssl_socket.sendall(request.encode("utf-8"))

        response = b''
        while True:
            data = ssl_socket.recv(1024)
            if not data:
                break
            response += data

        ssl_socket.close()
        
        soup = BeautifulSoup(response, 'html.parser') 


    return response

def return_content(response):
    if "application/json" in response.decode('latin-1')[:150]:
        json_response = "{" + response.decode('latin-1').split('{', 1)[1]
        dict_response = json_response.replace("\n", "").replace(" ", "").replace("\t", "").replace("\r", "").replace(":", ": ").replace(",", ", ")
        input_string = dict_response.strip('0')

        # Parse string to JSON
        pprint(json.loads(input_string))
        
    else:
        soup = BeautifulSoup(response, 'html.parser')
        content = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'ul', 'a'])
        for tag in content:
            if tag.name.startswith('h'):
                print("\n")
                print(tag.get_text().strip())
                print("\n")
            elif tag.name == 'p':
                print(tag.get_text().strip())
            elif tag.name == 'a':
                try:
                    if tag.get('href').startswith('http'):
                        print(tag.get_text().strip())
                        print("~~~", tag.get('href'))
                except:
                    pass
            elif tag.name == 'ul':
                for li in tag.find_all('li'):
                    print("-", li.get_text().strip())

def return_search_results(response):
    soup = BeautifulSoup(response, 'html.parser')
    print("\nSearch Results:")
    results = soup.find_all('li', class_='b_algo')
    for i, result in enumerate(results[:10]):
        print(f"{i+1}. {result.h2.get_text()}")
        link = result.find('cite')
        print(f"   {link.get_text()}")
        description = result.find('p')
        print(f"   {description.get_text()}\n")
    return

def print_error():
    print("Invalid arguments. Use 'go2web -h' for help.")
    return

def main():
    if sys.argv[1] == "-u":
        # try:
        if len(sys.argv) == 5:
            if sys.argv[3] == "-s":
                url = sys.argv[2]
                search_term = sys.argv[4]
                search_term = search_term.replace(" ", "+")
                print(f"Searching for: {search_term}")
                results = make_http_request(f"{url}/search?q={search_term}")
                return_content(results)
                http_cache(results)
            else:
                print_error()
                return    
        # except:
        elif len(sys.argv) == 3:
            url = sys.argv[2]
            content = make_http_request(url)
            return_content(content)
            http_cache(content)
            return
        else:
            print_error()
            return

    elif sys.argv[1] == "-s":
        if len(sys.argv) == 3:
            search_term = sys.argv[2]
            search_term = search_term.replace(" ", "+")
            print(f"Searching for: {search_term}")
            results = make_http_request(f"https://www.bing.com/search?q={search_term}")
            return_search_results(results)
            http_cache(results)
        else:
            print_error()
            return
    elif sys.argv[1] == "-h":
        print("Help:\n\
                go2web -u <URL>         # make an HTTP request to the specified URL and print the response\n\
                go2web -s <search-term> # make an HTTP request to search the term using a search engine and print top 10 results\n\
                go2web -h               # show this help \n")
        return
    else:
        print('go2web -h               # show help')
        return

if __name__ == "__main__":
    main()
